import { NextResponse } from 'next/server';
import { openai } from '@/lib/openai';

export const runtime = 'nodejs';

export async function POST(req: Request) {
    try {
        const body = await req.json();
        const { experience, photoCount, placeName } = body;

        if (!experience) {
            return NextResponse.json(
                { error: 'Experience data is required' },
                { status: 400 }
            );
        }

        const prompt = `
ë‹¹ì‹ ì€ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì´ì, ê°ì„±ì ì¸ ì—ì„¸ì´ ì‘ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì œê³µí•œ "ê²½í—˜ ì¡°ê°"ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ, í˜‘ì°¬ì„ ìœ ë„í•  ìˆ˜ ìˆëŠ” ê³ í’ˆì§ˆì˜ ë§›ì§‘ ë¦¬ë·° í¬ìŠ¤íŒ…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

[ì…ë ¥ ë°ì´í„°]
- ì¥ì†Œëª…: ${placeName}
- ì²«ì¸ìƒ: ${experience.firstImpression.join(', ')}
- ë§› í‰ì : ${experience.tasteRating}/5
- ê°€ì„±ë¹„ í‰ì : ${experience.valueRating}/100 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
- ì¥ì : ${experience.pros.join(', ')}
- ì•„ì‰¬ìš´ ì : ${experience.cons.join(', ')}
- í•œì¤„í‰: "${experience.oneLiner}"
- ì‚¬ì§„ ê°œìˆ˜: ${photoCount}ì¥

[ì‘ì„± ê°€ì´ë“œë¼ì¸ - D-I-A ë¡œì§]
1. **Experience (ê²½í—˜)**: ì œê³µëœ ë°ì´í„°ë¥¼ ë‹¨ìˆœ ë‚˜ì—´í•˜ì§€ ë§ê³ , ì‹¤ì œ ê²ªì€ ì—í”¼ì†Œë“œì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚´ì„¸ìš”.
   - ì˜ˆ: "ì§ì›ì´ ì¹œì ˆí•¨" -> "ë°”ìœ ì ì‹¬ì‹œê°„ì´ì—ˆëŠ”ë°ë„, ë¬¼ì”ì´ ë¹„ìë§ˆì ì±„ì›Œì£¼ì‹œëŠ” ì„¸ì‹¬í•¨ì— ê°ë™í–ˆì–´ìš”."
2. **Reliability (ì‹ ë¢°ì„±)**:
   - "ì•„ì‰¬ìš´ ì "ì„ ì†”ì§í•˜ê²Œ ì–¸ê¸‰í•˜ë˜, "ê·¸ë˜ë„ ë°©ë¬¸í•  ê°€ì¹˜ê°€ ìˆë‹¤"ëŠ” ì‹ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.
   - ë‚´ëˆë‚´ì‚° ëŠë‚Œì„ ê°•ì¡°í•˜ì„¸ìš”.
3. **Structure (êµ¬ì¡°)**:
   - **ì œëª©**: í´ë¦­ì„ ë¶€ë¥´ëŠ” ì œëª© 3ê°œ ì œì•ˆ.
   - **ë„ì…ë¶€**: ë°©ë¬¸ ë™ê¸°, ì²«ì¸ìƒ, ìœ„ì¹˜ ì •ë³´.
   - **ë³¸ë¬¸**: ë©”ë‰´/ë§›(êµ¬ì²´ì  ë¬˜ì‚¬), ë¶„ìœ„ê¸°, ì„œë¹„ìŠ¤.
   - **ë§ˆë¬´ë¦¬**: ì´í‰, ì¬ë°©ë¬¸ ì˜ì‚¬.
4. **Tone & Manner**:
   - 2030 ì—¬ì„± íƒ€ê²Ÿ, ê°ì„±ì ì´ê³  ì •ë³´ëŠ” ì •í™•í•˜ê²Œ.
   - ì´ëª¨ì§€ ì ì ˆ ì‚¬ìš© (âœ¨, ğŸ½ï¸).
   - ë¬¸ë‹¨ì€ ì§§ê²Œ.

[ì¶œë ¥ í˜•ì‹]
ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì´ì§€ë§Œ ë„¤ì´ë²„ ë¸”ë¡œê·¸ì— ë¶™ì—¬ë„£ê¸° ì¢‹ì€ í…ìŠ¤íŠ¸.
`;

        const completion = await openai.chat.completions.create({
            model: "gpt-4o",
            messages: [
                {
                    role: "system",
                    content: "ë‹¹ì‹ ì€ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ìƒìœ„ ë…¸ì¶œ ë¡œì§(D-I-A)ì„ ë§ˆìŠ¤í„°í•œ ì „ë¬¸ AI ì—ë””í„°ì…ë‹ˆë‹¤."
                },
                {
                    role: "user",
                    content: prompt
                }
            ],
            temperature: 0.7,
            max_tokens: 2500,
        });

        const content = completion.choices[0]?.message?.content || "ê¸€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.";

        return NextResponse.json({ content });

    } catch (error: any) {
        console.error('Error generating content:', error);
        return NextResponse.json(
            { error: error.message || 'Internal Server Error' },
            { status: 500 }
        );
    }
}
